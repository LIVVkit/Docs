<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">


<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>Developers workflow &#8212; LIVVkit 2.0.0 documentation</title>
    
    <link rel="stylesheet" href="_static/alabaster.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    './',
        VERSION:     '2.0.0',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="_static/jquery.js"></script>
    <script type="text/javascript" src="_static/underscore.js"></script>
    <script type="text/javascript" src="_static/doctools.js"></script>
    <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="top" title="LIVVkit 2.0.0 documentation" href="index.html" />
   
  <link rel="stylesheet" href="_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head>
  <body role="document">
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <div class="section" id="developers-workflow">
<h1>Developers workflow<a class="headerlink" href="#developers-workflow" title="Permalink to this headline">¶</a></h1>
<p>Using this workflow will allow you to perform a software <a class="reference external" href="VV-code-verification">code
verification</a> of model changes, and will
provide you with software <a class="reference external" href="VV-performance-validation">performance
validation</a> data of those changes.</p>
<p>Typically, this workflow will be used to compare the current state of a
model (<code class="docutils literal"><span class="pre">head</span></code> of the development branch <code class="docutils literal"><span class="pre">origin/develop</span></code>) with the
changes proposed in a pull request (<code class="docutils literal"><span class="pre">head</span></code> of a feature banch
<code class="docutils literal"><span class="pre">user/feature</span></code>). Here the <code class="docutils literal"><span class="pre">head</span></code> of <code class="docutils literal"><span class="pre">origin/develop</span></code> will be the
benchmark commit, and the <code class="docutils literal"><span class="pre">head</span></code> of a <code class="docutils literal"><span class="pre">user/feature</span></code> will be the
test commit. More generally, this is just a comparison across two
commits, where the benchmark commit id is <code class="docutils literal"><span class="pre">$ID_BENCH</span></code> (<code class="docutils literal"><span class="pre">ID_BENCH</span></code> is
an environment variable containing the commit id) and the test commit id
is <code class="docutils literal"><span class="pre">$ID_TEST</span></code>. We will use the commit ids below.</p>
<p>There are 3 steps to the development workflow:</p>
<ol class="arabic simple">
<li>Build the benchmark and test versions of the model</li>
<li>Generate the benchmark and test data</li>
<li>Use LIVVkit to analyze the data</li>
</ol>
<p>For this workflow, we will not assume that the benchmark data has
already been generated (unlike the <a class="reference external" href="Workflow-user">user-workflow</a>).
However, for a comparison of <code class="docutils literal"><span class="pre">origin/develop</span></code> to <code class="docutils literal"><span class="pre">user/feature</span></code>, the
benchmark data may already exist. In that case, the steps used to
generate the benchmark data can be skipped.</p>
<p>Note, LIVVkit is currently being developed and used in conjunction with
the Community Ice Sheet Model
(<a class="reference external" href="http://oceans11.lanl.gov/cism/documentation.html">CISM</a>), and these
instruction are described for use with CISM. CISM includes a <a class="reference external" href="Build-and-test">build and
test structure (BATS)</a> which is capable of building
CISM and then using that build to generate a dataset for use with
LIVVkit. LIVVkit can be easily extended to other ice sheet models by
creating a BATS for it &#8211; LIVVkit itself is model agnostic and only
analyzes the output data. Follow the link above for a detailed
description of BATS.</p>
<p>BATS is a relatively new feature and will only exist within recent
commits. We will first present a safe workflow, which does not assume
that BATS exists in either <code class="docutils literal"><span class="pre">$ID_BENCH</span></code> or <code class="docutils literal"><span class="pre">$ID_TEST</span></code>. After the
presentation of the safe workflow, we will briefly present the quick
workflow, where BATS exists in both <code class="docutils literal"><span class="pre">$ID_BENCH</span></code> and <code class="docutils literal"><span class="pre">$ID_TEST</span></code>.</p>
<div class="section" id="the-safe-workflow">
<h2>The safe workflow<a class="headerlink" href="#the-safe-workflow" title="Permalink to this headline">¶</a></h2>
<p>First, starting in a directory called <code class="docutils literal"><span class="pre">$BASE</span></code>, clone three versions of
CISM, one will contain <code class="docutils literal"><span class="pre">$ID_BENCH</span></code>, the second will contain
<code class="docutils literal"><span class="pre">$ID_TEST</span></code> and the third will contain BATS. Then, checkout the needed
commits.</p>
<div class="code sh highlight-default"><div class="highlight"><pre><span></span>git clone https://github.com/ACME-Climate/cism-piscees.git $BASE/cism-bench
git clone https://github.com/ACME-Climate/cism-piscees.git $BASE/cism-test
git clone https://github.com/ACME-Climate/cism-piscees.git $BASE/cism-bats

cd $BASE/cism-bench
git checkout -b bench $ID_BENCH

cd $BASE/cism-test
git checkout -b test $ID_TEST

cd $BASE/cism-bats
git checkout jhkennedy/regressions
</pre></div>
</div>
<p>Now, you can start building CISM and generating your data.</p>
<div class="section" id="build-the-benchmark-version-of-cism">
<h3>1. Build the benchmark version of CISM<a class="headerlink" href="#build-the-benchmark-version-of-cism" title="Permalink to this headline">¶</a></h3>
<p>Go to the benchmark version of CISM, and build CISM as you normally
would for your platform (<code class="docutils literal"><span class="pre">PLATFORM</span></code>) with your compiler of choice
(<code class="docutils literal"><span class="pre">COMPILER</span></code>). We use <code class="docutils literal"><span class="pre">PLATFORM=titan</span></code> and <code class="docutils literal"><span class="pre">COMPILER=gnu</span></code> for this
example. See the <a class="reference external" href="build-and-test">BATS</a> documentation for supported
platform and compiler combinations.</p>
<div class="code sh highlight-default"><div class="highlight"><pre><span></span>cd $BASE/cism-bench/builds/titan-gnu/
source titan-gnu-cmake
make -j 8
</pre></div>
</div>
<p>Repeat the above for the test version of CISM.</p>
<div class="code sh highlight-default"><div class="highlight"><pre><span></span>cd $BASE/cism-test/builds/titan-gnu/
source titan-gnu-cmake
make -j 8
</pre></div>
</div>
<p>Now you can generate the data.</p>
</div>
<div class="section" id="generating-the-benchmark-and-test-data">
<h3>2. Generating the benchmark and test data<a class="headerlink" href="#generating-the-benchmark-and-test-data" title="Permalink to this headline">¶</a></h3>
<p>Go to the BATS version of CISM, and generate the benchmark data.</p>
<div class="code sh highlight-default"><div class="highlight"><pre><span></span>cd $BASE/cism-bats/tests/regression
source setup_titan.bash
./build_and_test.py -p titan -c gnu --skip-build \
    -b $BASE/cism-bench/builds/titan-gnu \          # the benchmark build directory
    -o reg_bench \                                  # the benchmark data drectory
    --timing --performance
</pre></div>
</div>
<p>This will generate a <code class="docutils literal"><span class="pre">reg_bench</span></code> directory, which will contain a
<code class="docutils literal"><span class="pre">bash</span></code> script to submit all the test runs. Submit the runs.</p>
<div class="code sh highlight-default"><div class="highlight"><pre><span></span><span class="n">cd</span> <span class="n">reg_bench</span><span class="o">/</span><span class="n">titan</span><span class="o">-</span><span class="n">gnu</span><span class="o">/</span>
<span class="o">./</span><span class="n">submit_all_jobs</span><span class="o">.</span><span class="n">bash</span> <span class="o">|</span> <span class="n">tee</span> <span class="n">submit_all_jobs</span><span class="o">.</span><span class="n">log</span>
</pre></div>
</div>
<p>Now, you can repeat the above procedure, substituting <code class="docutils literal"><span class="pre">test</span></code> for
<code class="docutils literal"><span class="pre">bench</span></code> to generate the test data, as shown below.</p>
<div class="code sh highlight-default"><div class="highlight"><pre><span></span>cd $BASE/cism-bats/tests/regression
./build_and_test.py -p titan -c gnu --skip-build \
    -b $BASE/cism-test/builds/titan-gnu \           # the test build directory
    -o reg_test \                                   # the test data directory
    --timing --performance

cd reg_test/titan-gnu/
./submit_all_jobs.bash | tee submit_all_jobs.log
</pre></div>
</div>
<p>After all of your jobs have finished (job numbers will be found in the
two <code class="docutils literal"><span class="pre">submit_all_jobs.log</span></code> files), you will have a full set of
benchmark and test data for LIVVkit.</p>
<p>To see if you still have active running jobs, you can use the command</p>
<div class="code sh highlight-default"><div class="highlight"><pre><span></span><span class="n">showq</span> <span class="o">-</span><span class="n">u</span> <span class="n">USER</span>
</pre></div>
</div>
<p>to see your current jobs, where <code class="docutils literal"><span class="pre">USER</span></code> is your user name on titan (or
hopper at NERSC). For more information on using a job submission queue,
see the users guide for your platform (<a class="reference external" href="https://www.olcf.ornl.gov/support/system-user-guides/titan-user-guide/">titans users
guide</a>
and <a class="reference external" href="https://www.nersc.gov/users/computational-systems/hopper/">hoppers users
guide</a>).</p>
<p>After all the jobs are run, you may clean out the un-needed files from
the timing directory by running the two <code class="docutils literal"><span class="pre">clean_timing.bash</span></code> scripts:</p>
<div class="code sh highlight-default"><div class="highlight"><pre><span></span>cd $BASE/cism-bats/tests/regression/reg_bench/titan-gnu/
./clean_timing.bash

cd $BASE/cism-bats/tests/regression/reg_test/titan-gnu/
./clean_timing.bash
</pre></div>
</div>
<p>This process can be repeated for any number of platform and compiler
combinations. The two <code class="docutils literal"><span class="pre">reg_*</span></code> directories with then contain a number
of <code class="docutils literal"><span class="pre">PLATFORM-COMPILER</span></code> data directories.</p>
<p>Note: If these steps are performed on a regular mac or linux personal
computer, <code class="docutils literal"><span class="pre">./build_and_test.py</span></code> will immediately run the jobs instead
of generating a job submission script and will automatically clean out
the timing directory once the timing runs have finished (if applicable).
If <code class="docutils literal"><span class="pre">--performance</span></code> and <code class="docutils literal"><span class="pre">--timing</span></code> are both specified, a very large
amount of tests will be run, and it will likely take a long time.
Neither need to be run, but without at least the <code class="docutils literal"><span class="pre">--performance</span></code>
option specified, no performance validation data will be generated and
only code verification tests will be performed.</p>
</div>
<div class="section" id="use-livvkit-to-analyze-the-data">
<h3>3. Use LIVVkit to analyze the data<a class="headerlink" href="#use-livvkit-to-analyze-the-data" title="Permalink to this headline">¶</a></h3>
<p>Now that the benchmark and test data has been generated, you can run
LIVVkit. If you don&#8217;t already have the LIVVkit code, clone a copy into
your <code class="docutils literal"><span class="pre">$BASE</span></code> directory.</p>
<div class="code sh highlight-default"><div class="highlight"><pre><span></span>git clone https://github.com/ACME-Climate/LIVV.git $BASE/livv
</pre></div>
</div>
<p>Now, run LIVVkit.</p>
<div class="code sh highlight-default"><div class="highlight"><pre><span></span>cd $BASE/livv
git checkout develop
source setup_titan.bash
./livv.py -o www_${ID_BENCH}-${ID_TEST} \                      # output website
    -b $BASE/cism-bats/tests/regression/reg_bench/titan-gnu/ \ # test data
    -t $BASE/cism-bats/tests/regression/reg_test/titan-gnu/  \ # benchmark data
    -c &quot;Comparison of $ID_BENCH with $ID_TEST&quot;
    --performance
</pre></div>
</div>
<p>The <code class="docutils literal"><span class="pre">setup_titan.bash</span></code> script represents the last known &#8220;good&#8221;
combination of modules that works with LIVVkit. You may need to adjust
as these type of platforms change frequently. (There is also a
<code class="docutils literal"><span class="pre">setup_hopper.bash</span></code>).</p>
<p>Once LIVVkit completes, you can look at the analysis in your preferred
internet browser.</p>
<div class="code sh highlight-default"><div class="highlight"><pre><span></span>firefox www_${ID_BENCH}-${ID_TEST}/index.html
</pre></div>
</div>
<p>The can be repeated for any <code class="docutils literal"><span class="pre">PLATFORM-COMPILER</span></code> combinations that
exist within the <code class="docutils literal"><span class="pre">reg_*</span></code> directories. In fact, both the <code class="docutils literal"><span class="pre">-b</span></code> and
<code class="docutils literal"><span class="pre">-t</span></code> options can be pointed to any BATS data directory &#8211; you can even
do cross <code class="docutils literal"><span class="pre">PLATFORM</span></code> and/or <code class="docutils literal"><span class="pre">COMPILER</span></code> comparisons, or compare a
directory to itself. In the former case, bit-for-bit failures should be
<em>expected</em>, but the size of the differences and the performance
differences my be informative.</p>
<p>Note, this workflow can be simplified if BATS exists within the
benchmark, and test commit ids, as shown below.</p>
</div>
</div>
<div class="section" id="the-quick-workflow">
<h2>The quick workflow<a class="headerlink" href="#the-quick-workflow" title="Permalink to this headline">¶</a></h2>
<p>Todo.</p>
<div class="section" id="id1">
<h3>1. Build the benchmark version of CISM<a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h3>
<p>Todo.</p>
</div>
<div class="section" id="id2">
<h3>2. Generating the benchmark and test data<a class="headerlink" href="#id2" title="Permalink to this headline">¶</a></h3>
<p>Todo.</p>
</div>
<div class="section" id="id3">
<h3>3. Use LIVVkit to analyze the data<a class="headerlink" href="#id3" title="Permalink to this headline">¶</a></h3>
<p>Todo.</p>
</div>
</div>
</div>


          </div>
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
  <h3><a href="index.html">Table Of Contents</a></h3>
  <ul>
<li><a class="reference internal" href="#">Developers workflow</a><ul>
<li><a class="reference internal" href="#the-safe-workflow">The safe workflow</a><ul>
<li><a class="reference internal" href="#build-the-benchmark-version-of-cism">1. Build the benchmark version of CISM</a></li>
<li><a class="reference internal" href="#generating-the-benchmark-and-test-data">2. Generating the benchmark and test data</a></li>
<li><a class="reference internal" href="#use-livvkit-to-analyze-the-data">3. Use LIVVkit to analyze the data</a></li>
</ul>
</li>
<li><a class="reference internal" href="#the-quick-workflow">The quick workflow</a><ul>
<li><a class="reference internal" href="#id1">1. Build the benchmark version of CISM</a></li>
<li><a class="reference internal" href="#id2">2. Generating the benchmark and test data</a></li>
<li><a class="reference internal" href="#id3">3. Use LIVVkit to analyze the data</a></li>
</ul>
</li>
</ul>
</li>
</ul>
<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="index.html">Documentation overview</a><ul>
  </ul></li>
</ul>
</div>
  <div role="note" aria-label="source link">
    <h3>This Page</h3>
    <ul class="this-page-menu">
      <li><a href="_sources/Workflow-developer.txt"
            rel="nofollow">Show Source</a></li>
    </ul>
   </div>
<div id="searchbox" style="display: none" role="search">
  <h3>Quick search</h3>
    <form class="search" action="search.html" method="get">
      <div><input type="text" name="q" /></div>
      <div><input type="submit" value="Go" /></div>
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2016, Joseph H. Kennedy, Andrew R. Bennett, Katherine J. Evans.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 1.4.6</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.9</a>
      
      |
      <a href="_sources/Workflow-developer.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>